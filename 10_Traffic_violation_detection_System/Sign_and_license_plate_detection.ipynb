{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape.MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_dataset.pickle', 'rb') as f:data = pickle.load(f, encoding='latin1') \n",
    "data['y_train'] = to_categorical(data['y_train'], num_classes=43)\n",
    "data['y_validation'] = to_categorical(data['y_validation'], num_classes=43)\n",
    "\n",
    "data['x_train'] = np.transpose(data['x_train'], (0, 2, 3, 1))\n",
    "data['x_validation'] = np.transpose(data['x_validation'], (0, 2, 3, 1))\n",
    "data['x_test'] = np.transpose(data['x_test'], (0, 2, 3, 1))\n",
    "\n",
    "for key, value in data.items():\n",
    "    if key == 'labels':\n",
    "        print(f'{key}: {len(value)}')\n",
    "    else:\n",
    "        print(f'{key}: {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "epochs = 15\n",
    "def convert_to_grid(input_images):\n",
    "    total_images, image_height, image_width, channels = input_images.shape\n",
    "    grid_size = int(np.ceil(np.sqrt(total_images)))\n",
    "    grid_height = image_height * grid_size + (grid_size - 1)\n",
    "    grid_width = image_width * grid_size + (grid_size - 1)\n",
    "    image_grid = np.zeros((grid_height, grid_width, channels)) + 255\n",
    "    image_index = 0\n",
    "    row_start, row_end = 0, image_height\n",
    "    for row in range(grid_size):\n",
    "        col_start, col_end = 0, image_width\n",
    "        for col in range(grid_size):\n",
    "            if image_index < total_images:\n",
    "                current_image = input_images[image_index]\n",
    "                min_val, max_val = np.min(current_image), np.max(current_image)\n",
    "                image_grid[row_start:row_end, col_start:col_end] = 255.0 * (current_image - min_val) / (max_val - min_val)\n",
    "                image_index += 1\n",
    "            col_start += image_width + 1\n",
    "            col_end += image_width + 1\n",
    "        row_start += image_height + 1\n",
    "        row_end += image_height + 1\n",
    "    return image_grid\n",
    "\n",
    "examples = data['x_train'][:81, :, :, :]\n",
    "print(examples.shape)\n",
    "fig = plt.figure()\n",
    "grid = convert_to_grid(examples)\n",
    "plt.imshow(grid.astype('uint8'), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seq = Sequential()\n",
    "data_seq.add(MaxPool2D(pool_size=2))\n",
    "data_seq.add(Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "data_seq.add(Dense(500, activation='relu'))\n",
    "data_seq.add(Dense(43, activation='softmax'))\n",
    "data_seq.add(Flatten())\n",
    "data_seq.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate_stuff = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\n",
    "h = data_seq.fit(data['x_train'][:10], data['y_train'][:10],batch_size=5, epochs = epochs,validation_data = (data['x_validation'], data['y_validation']),callbacks=[learn_rate_stuff], verbose=1)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15.0, 5.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(h.history['accuracy'], '-o', linewidth=3.0)\n",
    "plt.plot(h.history['val_accuracy'], '-o', linewidth=3.0)\n",
    "plt.title('Overfitting small data', fontsize=22)\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.xlabel('Epoch', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.tick_params(labelsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [3, 5, 9, 13, 15, 19, 23, 25, 31]\n",
    "data_seq = [0] * len(filters)\n",
    "for i in range(len(data_seq)):\n",
    "    data_seq[i] = Sequential()\n",
    "    data_seq[i].add(Conv2D(32, kernel_size=filters[i], padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "    data_seq[i].add(MaxPool2D(pool_size=2))\n",
    "    data_seq[i].add(Flatten())\n",
    "    data_seq[i].add(Dense(500, activation='relu'))\n",
    "    data_seq[i].add(Dense(43, activation='softmax'))\n",
    "    data_seq[i].compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\n",
    "epochs = 5\n",
    "h = [0] * len(data_seq)\n",
    "for i in range(len(h)):\n",
    "    h[i] = data_seq[i].fit(data['x_train'], data['y_train'],batch_size=5, epochs = epochs,validation_data = (data['x_validation'], data['y_validation']),callbacks=[annealer], verbose=0)\n",
    "    print('Model with filters {0:d}x{0:d}, epochs={1:d}, training accuracy={2:.5f}, validation accuracy={3:.5f}'.\\\n",
    "      format(filters[i], epochs, max(h[i].history['accuracy']), max(h[i].history['val_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15.0, 15.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(h[8].history['accuracy'], '-o', linewidth=3.0)\n",
    "plt.plot(h[7].history['accuracy'], '-s', linewidth=3.0)\n",
    "plt.plot(h[6].history['accuracy'], '-D', linewidth=3.0)\n",
    "plt.plot(h[5].history['accuracy'], '-D', linewidth=3.0)\n",
    "plt.plot(h[4].history['accuracy'], '-o', linewidth=3.0)\n",
    "plt.plot(h[3].history['accuracy'], '-o', linewidth=3.0)\n",
    "plt.plot(h[2].history['accuracy'], '-o', linewidth=3.0)\n",
    "plt.plot(h[1].history['accuracy'], '-o', linewidth=3.0)\n",
    "plt.plot(h[0].history['accuracy'], '-o', linewidth=3.0)\n",
    "plt.legend(['filter 31', 'filter 25', 'filter 23', 'filter 19', 'filter 15', 'filter 13', 'filter 9', 'filter 5', 'filter 3'], loc='lower right', fontsize='xx-large', borderpad=2)\n",
    "plt.xlabel('Epoch', fontsize=20, fontname='Times New Roman')\n",
    "plt.ylabel('Training accuracy', fontsize=20, fontname='Times New Roman')\n",
    "plt.yscale('linear') \n",
    "plt.ylim(0.85, 1.0)\n",
    "plt.xlim(0.5, 5.3) \n",
    "plt.title('accuracy for different sizes of filters', fontsize=22)\n",
    "plt.tick_params(labelsize=18)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(h[8].history['val_accuracy'], '-o', linewidth=3.0)\n",
    "plt.plot(h[7].history['val_accuracy'], '-s', linewidth=3.0)\n",
    "plt.plot(h[6].history['val_accuracy'], '-D', linewidth=3.0)\n",
    "plt.plot(h[5].history['val_accuracy'], '-D', linewidth=3.0)\n",
    "plt.plot(h[4].history['val_accuracy'], '-o', linewidth=3.0)\n",
    "plt.plot(h[3].history['val_accuracy'], '-o', linewidth=3.0)\n",
    "plt.plot(h[2].history['val_accuracy'], '-o', linewidth=3.0)\n",
    "plt.plot(h[1].history['val_accuracy'], '-o', linewidth=3.0)\n",
    "plt.plot(h[0].history['val_accuracy'], '-o', linewidth=3.0)\n",
    "plt.legend(['filter 31', 'filter 25', 'filter 23', 'filter 19', 'filter 15', 'filter 13', 'filter 9', 'filter 5', 'filter 3'], loc='lower right', fontsize='xx-large', borderpad=2)\n",
    "plt.xlabel('Epoch', fontsize=20, fontname='Times New Roman')\n",
    "plt.ylabel('Validation accuracyuracy', fontsize=20, fontname='Times New Roman')\n",
    "plt.yscale('linear')\n",
    "plt.ylim(0.75, 0.9)\n",
    "plt.xlim(0.5, 5.3)\n",
    "plt.tick_params(labelsize=18)\n",
    "plt.show()\n",
    "for i in range(len(h)):\n",
    "    print('data2 filter {0:d} training accuracy = {1:.5f}'.\\\n",
    "          format(filters[i], np.max(h[i].history['accuracy'])))\n",
    "\n",
    "print()\n",
    "for i in range(len(h)):\n",
    "    print('data2 filter {0:d} validation accuracy = {1:.5f}'.\\\n",
    "          format(filters[i], np.max(h[i].history['val_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_seq)):\n",
    "    temp = data_seq[i].predict(data['x_test'])\n",
    "    temp = np.argmax(temp, axis=1)\n",
    "    temp = np.mean(temp == data['y_test'])\n",
    "    print('data2 filter {0:d} testing accuracy = {1:.5f}'.format(filters[i], temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_seq)):\n",
    "    start = timer()\n",
    "    temp = data_seq[i].predict(data['x_test'][:1, :, :, :])\n",
    "    end = timer()\n",
    "    print('data2 filter {0:d} classification time = {1:.5f}'.format(filters[i], end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_seq)):\n",
    "    w = data_seq[i].get_weights()\n",
    "    print(w[0].shape)\n",
    "    temp = w[0].transpose(3, 0, 1, 2)\n",
    "    print(temp.shape) \n",
    "    fig = plt.figure()\n",
    "    grid = convert_to_grid(temp)\n",
    "    plt.imshow(grid.astype('uint8'), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.gcf().set_size_inches(10, 10)\n",
    "    name = 'Trained filters ' + str(filters[i]) + 'x' + str(filters[i])\n",
    "    plt.title(name, fontsize=18)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "License plate detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_cascade = cv2.CascadeClassifier('Vehicle-Detection/archive/indian_license_plate.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_plate(img, text=''):\n",
    "    plate_img = img.copy()\n",
    "    roi = img.copy()\n",
    "    plate_rect = plate_cascade.detectMultiScale(plate_img, scaleFactor = 1.2, minNeighbors = 7)\n",
    "    for (x,y,w,h) in plate_rect:\n",
    "        roi_ = roi[y:y+h, x:x+w, :] \n",
    "        plate = roi[y:y+h, x:x+w, :]\n",
    "        cv2.rectangle(plate_img, (x+2,y), (x+w-3, y+h-5), (51,181,155), 3)\n",
    "    if text!='':plate_img = cv2.putText(plate_img, text, (x-w//2,y-h//2),cv2.FONT_HERSHEY_COMPLEX_SMALL , 0.5, (51,181,155), 1, cv2.LINE_AA)\n",
    "    return plate_img, plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img_, title=''):\n",
    "    img = cv2.cvtColor(img_, cv2.COLOR_BGR2RGB)\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "img = cv2.imread('/home/lakshya/ML/Vehicle-Detection/archive/car.jpg')\n",
    "display(img, 'input image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_img, plate = detect_plate(img)\n",
    "display(output_img, 'detected license plate in the input image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plate, 'extracted license plate from the image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_contours(size_range, image):\n",
    "    contours, _ = cv2.findContours(image.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    min_width = size_range[0]\n",
    "    max_width = size_range[1]\n",
    "    min_height = size_range[2]\n",
    "    max_height = size_range[3]\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:15]\n",
    "    output_image = cv2.imread('contour.jpg')\n",
    "    contour_x_positions = []\n",
    "    valid_contours = []\n",
    "    processed_characters = []\n",
    "    for contour in contours:\n",
    "        x, y, width, height = cv2.boundingRect(contour)\n",
    "        if min_width < width < max_width and min_height < height < max_height:\n",
    "            contour_x_positions.append(x)\n",
    "            character_template = np.zeros((44, 24))\n",
    "            character = image[y:y+height, x:x+width]\n",
    "            character = cv2.resize(character, (20, 40))\n",
    "            cv2.rectangle(output_image, (x, y), (width+x, y+height), (50, 21, 200), 2)\n",
    "            plt.imshow(output_image, cmap='gray')\n",
    "            character = cv2.subtract(255, character)\n",
    "            character_template[2:42, 2:22] = character\n",
    "            character_template[0:2, :] = 0\n",
    "            character_template[:, 0:2] = 0\n",
    "            character_template[42:44, :] = 0\n",
    "            character_template[:, 22:24] = 0\n",
    "            processed_characters.append(character_template)\n",
    "    plt.show()\n",
    "    ordered_indices = sorted(range(len(contour_x_positions)), key=lambda i: contour_x_positions[i])\n",
    "    ordered_characters = [processed_characters[i] for i in ordered_indices]\n",
    "    processed_characters = np.array(ordered_characters)\n",
    "    return processed_characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def segment_characters(input_image):\n",
    "    resized_image = cv2.resize(input_image, (333, 75))\n",
    "    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_image = cv2.threshold(gray_image, 200, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    processed_image = cv2.dilate(cv2.erode(binary_image, (3, 3)), (3, 3))\n",
    "    image_width = processed_image.shape[0]\n",
    "    image_height = processed_image.shape[1]\n",
    "    processed_image[0:3, :] = 255\n",
    "    processed_image[:, 0:3] = 255\n",
    "    processed_image[72:75, :] = 255\n",
    "    processed_image[:, 330:333] = 255\n",
    "    contour_dimensions = [image_width / 6, image_width / 2, image_height / 10, 2 * image_height / 3]\n",
    "    plt.imshow(processed_image, cmap='gray')\n",
    "    plt.show()\n",
    "    cv2.imwrite('contour_output.jpg', processed_image)\n",
    "    characters = find_contours(contour_dimensions, processed_image)\n",
    "    return characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = segment_characters(plate)\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(char[i], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as BackEnd\n",
    "train_generator_data = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1)\n",
    "path = 'Vehicle-Detection/archive/data/data'\n",
    "validation_generator = train_generator_data.flow_from_directory(path+'/val',  target_size=(28,28), class_mode='sparse')\n",
    "train_generator = train_generator_data.flow_from_directory(path+'/train',target_size=(28,28),batch_size=1,class_mode='sparse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(y, y_pred):\n",
    "    return f1_score(y, tf.math.argmax(y_pred, axis=1), average='micro') \n",
    "def custom_f1score(y, y_pred):\n",
    "    return tf.py_function(f1score, (y, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BackEnd.clear_session()\n",
    "data_seq = Sequential()\n",
    "data_seq.add(Conv2D(16, (22,22), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "data_seq.add(Conv2D(32, (16,16), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "data_seq.add(Conv2D(64, (8,8), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "data_seq.add(Conv2D(64, (4,4), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "data_seq.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "data_seq.add(Dropout(0.4))\n",
    "data_seq.add(Flatten())\n",
    "data_seq.add(Dense(128, activation='relu'))\n",
    "data_seq.add(Dense(36, activation='softmax'))\n",
    "data_seq.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(lr=0.0001), metrics=[custom_f1score])\n",
    "data_seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stop_training_callback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_custom_f1score') > 0.99):self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "callbacks = [stop_training_callback()]\n",
    "data_seq.fit_generator(train_generator,steps_per_epoch = train_generator.samples // batch_size,validation_data = validation_generator, epochs = 80, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fix_dimension(image): \n",
    "  zeroes_image = np.zeros((28,28,3))\n",
    "  for i in range(3):\n",
    "    zeroes_image[:,:,i] = image\n",
    "  return zeroes_image\n",
    "def show_results():\n",
    "    dictt = {}\n",
    "    char = 'QWERTYUIOPLKJHGFDSAZXCVBNM1234567890'\n",
    "    for i,c in enumerate(char):\n",
    "        dictt[i] = c\n",
    "    output = []\n",
    "    for _,chr in enumerate(char):\n",
    "      lol_image = cv2.resize(chr, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "      image = fix_dimension(lol_image)\n",
    "      image = image.reshape(1, 28, 28, 3)\n",
    "      y_prob = model.predict(image)\n",
    "      y_class = np.argmax(y_prob, axis=-1)\n",
    "      character = dictt[y_class[0]] \n",
    "      output.append(character)\n",
    "        \n",
    "    detected_plate = ''.join(output)\n",
    "    \n",
    "    return detected_plate\n",
    "\n",
    "print(show_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for index,chr in enumerate(char):\n",
    "    image = cv2.resize(chr, (28,28), interpolation=cv2.INTER_AREA)\n",
    "    plt.subplot(3,4,index+1)\n",
    "    plt.imshow(image,cmap='gray')\n",
    "    plt.title(f'predicted: {show_results()[i]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
